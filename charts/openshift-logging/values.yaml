---
# Type can value elasticsearch or loki
type: elasticsearch

logforwarderConfig:
  enabled: true
  syncwave: '5'

loggingConfig:
  enabled: true
  #Parameters to Elastic Search config
  es:
    storagesize: 200G
    storageclass: ocs-storagecluster-ceph-rbd
    nodes: 3
    limits:
      mem: 8Gi
    requests:
      mem: 4Gi
    redundancyPolicy: SingleRedundancy
    retentionPolicy:
      application:
        maxAge: 1d
      audit:
        maxAge: 1d
      infra:
        maxAge: 1d

  syncwave: '4'
  # Indicator if the resource is 'Managed' or 'Unmanaged' by the operator
  # managementState: Managed
  # Specification of the Log Storage component for loki
  loki:
    # The Type of Log Storage to configure. The operator currently supports either using ElasticSearch managed by elasticsearch-operator or Loki managed by loki-operator (LokiStack) as a default log store.
    type: lokistack
    # type: elasticsearch
    # Name of the LokiStack resource.
    lokistack: logging-loki

    retentionPolicy:
      application:
        maxAge: 1d
      audit:
        maxAge: 1d
      infra:
        maxAge: 1d
    visualization:
      # The type of Visualization to configure
      # Could be either Kibana or ocp-console
      type: ocp-console
    collection:
      # The type of Log Collection to configure
      # Vector in case of Loki...
      type: vector
      # The resource requirements for the collector
      # resources:
      #   limits:
      #     cpu: '500m'
      #     memory: '1Gi'
      #     ephemeral-storage: '50Mi'
      #   requests:
      #     cpu: '500m'
      #     memory: '1Gi'
      #     ephemeral-storage: '500Mi'
      # Define the tolerations the Pods will accept
      # tolerations:
      #  - effect: NoSchedule
      #    key: cluster.ocs.openshift.io/openshift-storage
      #    operator: Equal
      #    value: ''

# Install Operator Compliance Operator
# Deploys Operator --> Subscription and Operatorgroup
# Syncwave: 0
helper-operator:
  operators:
    elasticsearch-operator:
      enabled: true
      syncwave: '0'
      namespace:
        name: openshift-operators-redhat
        create: true
      subscription:
        approval: Automatic
        operatorName: elasticsearch-operator
        source: redhat-operators
        sourceNamespace: openshift-marketplace
      operatorgroup:
        notownnamespace: true
        create: true

    loki-operator:
      enabled: false
      syncwave: '0'
      namespace:
        name: openshift-operators-redhat
        create: true
      subscription:
        channel: stable-5.9
        approval: Automatic
        operatorName: loki-operator
        source: redhat-operators
        sourceNamespace: openshift-marketplace
      operatorgroup:
        notownnamespace: true
        create: true

    cluster-logging-operator:
      enabled: true
      syncwave: '0'
      namespace:
        name: openshift-logging
        create: true
      subscription:
        approval: Automatic
        operatorName: cluster-logging
        source: redhat-operators
        sourceNamespace: openshift-marketplace
      operatorgroup:
        create: true

helper-status-checker:
  enabled: false

  checks:

    - operatorName: cluster-logging
      namespace:
        name: openshift-logging
      syncwave: 3

      serviceAccount:
        name: "status-checker-logging"

    - operatorName: loki-operator
      namespace:
        name: openshift-logging
      syncwave: 3

      serviceAccount:
        name: "status-checker-loki"


helper-objectstore:
  ######################################
  # Configures OpenShift Data Foundation
  # This will create a BackingStore, BucketClaim and BucketClass
  #
  # Documentation: https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.10/html-single/managing_hybrid_and_multicloud_resources/index#creating-a-local-Persistent-Volume-backed-backingstore_rhodf
  ######################################

  # -- Enable objectstore configuration
  # @default -- false
  enabled: false

  # -- Syncwave for Argo CD
  # @default - 1
  syncwave: 1

  # -- Name of the BackingStore
  backingstore_name: backingstore

  # -- Size of the BackingStore that each volume shall have.
  backingstore_size: 700Gi

  # -- CPU Limit for the Noobaa Pod
  # @default -- 500m
  limits_cpu: 500m

  # -- Memory Limit for the Noobaa Pod.
  # @default -- 2Gi
  limits_memory: 2Gi

  pvPool:
    # -- Number of volumes that shall be used
    # @default -- 1
    numOfVolumes: 1

    # Type of BackingStore. Currently pv-pool is the only one supported by this Helm Chart.
    # @default -- pv-pool
    type: pv-pool

  # -- The StorageClass the BackingStore is based on
  baseStorageClass: openshift-storage.noobaa.io

  # -- Name of the StorageClass that shall be created for the bucket.
  storageclass_name: bucket-storage-class

  # Bucket that shall be created
  bucket:
    # -- Shall a new bucket be enabled?
    # @default -- false
    enabled: false

    # -- Name of the bucket that shall be created
    name: logging-loki-s3

    # -- Target Namespace for that bucket.
    namespace: openshift-logging

    # -- Syncwave for bucketclaim creation. This should be done very early, but it depends on ODF.
    # @default -- 2
    syncwave: '0'

    # -- Name of the storageclass for our bucket
    # @default -- openshift-storage.noobaa.io
    storageclass: openshift-storage.noobaa.io

helper-loki-bucket-secret:

  enabled: false

  # -- Syncwave for Argo CD.
  # @default -- 3
  syncwave: '1'

  # -- Namespace where LokiStack is deployed and where the Secret shall be created.
  namespace: openshift-logging

  # -- Name of Secret that shall be created.
  secretname: logging-loki-s3-secret

  # Bucket Configuration
  bucket:
    # -- Name of the Bucket shall has been created.
    name: logging-loki-s3


helper-lokistack:
  # -- Enable or disable LokiStack configuration
  # @default -- false
  enabled: false

  # -- Name of the LokiStack object
  name: logging-loki

  # -- Namespace of the LokiStack object
  namespace: openshift-logging

  # -- Syncwave for the LokiStack object.
  # @default -- 3
  syncwave: '3'

  # -- This is for log streams only, not the retention of the object store. Data retention must be configured on the bucket.
  global_retention_days: 4

  # Setting for storage
  storage:

    # -- Size defines one of the supported Loki deployment scale out sizes.
    # Can be either:
    #   - 1x.extra-small (Default)
    #   - 1x.small
    #   - 1x.medium
    # @default -- 1x.extra-small
    size: 1x.extra-small

    # Secret for object storage authentication. Name of a secret in the same namespace as the LokiStack custom resource.
    secret:

      # -- Name of a secret in the namespace configured for object storage secrets.
      name: logging-loki-s3-secret

      # Type of object storage that should be used
      # Can bei either:
      #  - swift
      #  - azure
      #  - s3 (default)
      #  - alibabacloud
      #  - gcs
      # -- Type of object storage that should be used
      # @default -- s3
      type: s3

    # Schemas for reading and writing logs.
    schemas:
       # -- Version for writing and reading logs.
       # Can be v11 or v12
       # @default -- v12
      - version: v12
        # -- EffectiveDate is the date in UTC that the schema will be applied on. To ensure readibility of logs, this date should be before the current date in UTC.
        # @default -- 2022-06-01
        effectiveDate: "2024-05-16"

  # -- Storage class name defines the storage class for ingester/querier PVCs.
  # @default -- gp3-csi
  storageclassname: ocs-storagecluster-ceph-rbd

  # -- Mode defines the mode in which lokistack-gateway component will be configured.
  # Can be either: static (default), dynamic, openshift-logging, openshift-network
  # @default -- static
  mode: openshift-logging

  # -- Control pod placement for LokiStack components. You can define a list of tolerations for the following components:
  # compactor, distributer, gateway, indexGateway, ingester, querier, queryFrontend, ruler
  podPlacements: {}

  # podPlacements:
  #  # Pod placement of compactor
  #  compactor:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of distributor
  #  distributor:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of gateway
  #  gateway:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of indexGateway
  #  indexGateway:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of ingester
  #  ingester:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of querier
  #  querier:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of queryFrontend
  #  queryFrontend:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #  # Pod placement of ruler
  #  ruler:
  #    tolerations:
  #      - effect: NoSchedule
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
  #      - effect: NoExecute
  #        key: node-role.kubernetes.io/infra
  #        operator: Equal
  #        value: reserved
